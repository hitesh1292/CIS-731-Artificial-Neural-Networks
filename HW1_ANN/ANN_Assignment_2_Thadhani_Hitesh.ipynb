{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the charges of the medical insurance for a person based on various attributes of both categorical and numerical in nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries of Keras and sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed for the tensorflow\n",
    "\n",
    "from tensorflow.python import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "\n",
    "df = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Details about the attributes including data type and non null count\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the age attribute to float64 to make all the input features of the same datatype \n",
    "\n",
    "df['age'] = df['age'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the children attribute to float64 to make all the input features of the same datatype \n",
    "\n",
    "df['children'] = df['children'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918  13270.422265\n",
       "std      14.049960     6.098187     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attributes distribution in terms of mean, median and IQR\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of the columns of the df dataframe\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot Encoding/Dummy for the categorical values to convert them into numerical values as NN expects the input to be numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for each of the categorical input variables\n",
    "\n",
    "df_2 = pd.get_dummies(df, columns = ['sex','smoker','region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the order of the columns for easy input and target features bifurcation\n",
    "\n",
    "cols = ['age','children','bmi','sex_female','sex_male','smoker_no','smoker_yes','region_northeast','region_northwest','region_southeast','region_southwest','charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>children</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.770</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.920</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  children     bmi  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0     19.0       0.0  27.900           1         0          0           1   \n",
       "1     18.0       1.0  33.770           0         1          1           0   \n",
       "2     28.0       3.0  33.000           0         1          1           0   \n",
       "3     33.0       0.0  22.705           0         1          1           0   \n",
       "4     32.0       0.0  28.880           0         1          1           0   \n",
       "...    ...       ...     ...         ...       ...        ...         ...   \n",
       "1333  50.0       3.0  30.970           0         1          1           0   \n",
       "1334  18.0       0.0  31.920           1         0          1           0   \n",
       "1335  18.0       0.0  36.850           1         0          1           0   \n",
       "1336  21.0       0.0  25.800           1         0          1           0   \n",
       "1337  61.0       0.0  29.070           1         0          0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \\\n",
       "0                    0                 0                 0                 1   \n",
       "1                    0                 0                 1                 0   \n",
       "2                    0                 0                 1                 0   \n",
       "3                    0                 1                 0                 0   \n",
       "4                    0                 1                 0                 0   \n",
       "...                ...               ...               ...               ...   \n",
       "1333                 0                 1                 0                 0   \n",
       "1334                 1                 0                 0                 0   \n",
       "1335                 0                 0                 1                 0   \n",
       "1336                 0                 0                 0                 1   \n",
       "1337                 0                 1                 0                 0   \n",
       "\n",
       "          charges  \n",
       "0     16884.92400  \n",
       "1      1725.55230  \n",
       "2      4449.46200  \n",
       "3     21984.47061  \n",
       "4      3866.85520  \n",
       "...           ...  \n",
       "1333  10600.54830  \n",
       "1334   2205.98080  \n",
       "1335   1629.83350  \n",
       "1336   2007.94500  \n",
       "1337  29141.36030  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and Output Features Pre-Processing including Normalizing and Train and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining the Input features\n",
    "\n",
    "X = df_2.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>children</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.770</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.920</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.850</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  children     bmi  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0     19.0       0.0  27.900           1         0          0           1   \n",
       "1     18.0       1.0  33.770           0         1          1           0   \n",
       "2     28.0       3.0  33.000           0         1          1           0   \n",
       "3     33.0       0.0  22.705           0         1          1           0   \n",
       "4     32.0       0.0  28.880           0         1          1           0   \n",
       "...    ...       ...     ...         ...       ...        ...         ...   \n",
       "1333  50.0       3.0  30.970           0         1          1           0   \n",
       "1334  18.0       0.0  31.920           1         0          1           0   \n",
       "1335  18.0       0.0  36.850           1         0          1           0   \n",
       "1336  21.0       0.0  25.800           1         0          1           0   \n",
       "1337  61.0       0.0  29.070           1         0          0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 0                 1  \n",
       "1                    0                 0                 1                 0  \n",
       "2                    0                 0                 1                 0  \n",
       "3                    0                 1                 0                 0  \n",
       "4                    0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1333                 0                 1                 0                 0  \n",
       "1334                 1                 0                 0                 0  \n",
       "1335                 0                 0                 1                 0  \n",
       "1336                 0                 0                 0                 1  \n",
       "1337                 0                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the target feature\n",
    "\n",
    "y = df_2[['charges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          charges\n",
       "0     16884.92400\n",
       "1      1725.55230\n",
       "2      4449.46200\n",
       "3     21984.47061\n",
       "4      3866.85520\n",
       "...           ...\n",
       "1333  10600.54830\n",
       "1334   2205.98080\n",
       "1335   1629.83350\n",
       "1336   2007.94500\n",
       "1337  29141.36030\n",
       "\n",
       "[1338 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the MinMaxScaler for normalizing the input and output features\n",
    "\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the input features \n",
    "\n",
    "X = minmax.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the target feature\n",
    "\n",
    "y = minmax.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into 80:20 ratio with 80% as training data and 20% as validation data\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input Train data: (1070, 11)\n",
      "Shape of Output Train data: (1070, 1)\n",
      "Shape of Input Validation data: (268, 11)\n",
      "Shape of Output Validation data: (268, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the Input and Output Train and Validation data\n",
    "\n",
    "print('Shape of Input Train data:',X_train.shape)\n",
    "print('Shape of Output Train data:',y_train.shape)\n",
    "print('Shape of Input Validation data:',X_val.shape)\n",
    "print('Shape of Output Validation data:',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing the number of hidden layers keeping the number of weights in the hidden layers constant here 2d d=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 22)                264       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Keras Neural Networks Model with Input dimension as 11 and 1 Hidden layer with sigmoid activation function and 1 output layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(22, input_dim=X.shape[1], kernel_initializer='normal',use_bias=True, activation='sigmoid')) # 22 nodes in 1 hidden layer\n",
    "model.add(Dense(1,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 22)                264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22)                506       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 793\n",
      "Trainable params: 793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Keras Neural Networks Model with Input dimension as 11 and 2 Hidden layers with sigmoid activation function and 1 output layer\n",
    "\n",
    "model_layer_1 = Sequential()\n",
    "model_layer_1.add(Dense(22, input_dim=X.shape[1], kernel_initializer='normal',use_bias=True, activation='sigmoid')) # 22 nodes in 1st hidden layer\n",
    "model_layer_1.add(Dense(22, activation='sigmoid',use_bias=True)) # 22 nodes in the 2nd hidden layer\n",
    "model_layer_1.add(Dense(1,))\n",
    "model_layer_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 22)                264       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 22)                506       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 22)                506       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 1,299\n",
      "Trainable params: 1,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Keras Neural Networks Model with Input dimension as 11 and 3 Hidden layers with sigmoid activation function and 1 output layer\n",
    "\n",
    "model_layer_2 = Sequential()\n",
    "model_layer_2.add(Dense(22, input_dim=X.shape[1], kernel_initializer='normal',use_bias=True, activation='sigmoid')) # 22 nodes in 1st hidden layer\n",
    "model_layer_2.add(Dense(22, activation='sigmoid',use_bias=True)) # 22 nodes in 2nd hidden layer\n",
    "model_layer_2.add(Dense(22, activation='sigmoid',use_bias=True)) # 22 nodes in 3rd hidden layer\n",
    "model_layer_2.add(Dense(1,))\n",
    "model_layer_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and Metrics to be used for evaluation as MSE and Optimizer as Adam for model with 1 hidden layer\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and Metrics to be used for evaluation as MSE and Optimizer as Adam for model with 2 hidden layers\n",
    "\n",
    "model_layer_1.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and Metrics to be used for evaluation as MSE and Optimizer as Adam for model with 3 hidden layers\n",
    "\n",
    "model_layer_2.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the 3 models with different number of hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n"
     ]
    }
   ],
   "source": [
    "# Training the NN model with scaled Input and Output with 100 Epochs and batch_size of 50 to see the MSE at each epoch \n",
    "# for training and validation split of the data for model with 1 hidden layer\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1057 - mse: 0.1057 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0321 - val_mse: 0.0321\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0274 - val_mse: 0.0274\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0252 - mse: 0.0252 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n"
     ]
    }
   ],
   "source": [
    "# Training the NN model with scaled Input and Output with 100 Epochs and batch_size of 50 to see the MSE at each epoch \n",
    "# for training and validation split of the data for model with 2 hidden layers\n",
    "\n",
    "history_layer_1 = model_layer_1.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1928 - mse: 0.1928 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0443 - val_mse: 0.0443\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0386 - val_mse: 0.0386\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0329 - val_mse: 0.0329\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0084 - val_mse: 0.0084\n"
     ]
    }
   ],
   "source": [
    "# Training the NN model with scaled Input and Output with 100 Epochs and batch_size of 50 to see the MSE at each epoch \n",
    "# for training and validation split of the data for model with 3 hidden layers\n",
    "\n",
    "history_layer_2 = model_layer_2.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the product of number of weights, number of epochs and number of data points in each batch=50\n",
    "# for using it as Computational Cost for model with 1 hidden layer\n",
    "\n",
    "epoch_x_mul_1 = []\n",
    "for i in range (1,(len(history.epoch)+1)):\n",
    "    epoch_x_mul_1.append(i * model.count_params() * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the product of number of weights, number of epochs and number of data points in each batch=50\n",
    "# for using it as Computational Cost for model with 2 hidden layers\n",
    "\n",
    "epoch_x_mul_2 = []\n",
    "for i in range (1,(len(history_layer_1.epoch)+1)):\n",
    "    epoch_x_mul_2.append(i * model_layer_1.count_params() * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the product of number of weights, number of epochs and number of data points in each batch=50\n",
    "# for using it as Computational Cost for model with 3 hidden layers\n",
    "\n",
    "epoch_x_mul_3 = []\n",
    "for i in range (1,(len(history_layer_2.epoch)+1)):\n",
    "    epoch_x_mul_3.append(i * model_layer_2.count_params() * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation mse for model with 1 hidden layer assigned to a variable\n",
    "\n",
    "MSE_y_val = history.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation mse for model with 2 hidden layers assigned to a variable\n",
    "\n",
    "MSE_y_val_layer = history_layer_1.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation mse for model with 3 hidden layers assigned to a variable\n",
    "\n",
    "MSE_y_val_layer_2 = history_layer_2.history['val_mse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Results Graph showing Best Validation MSE(lowest) obtained for model with 3 hidden layers and 22 nodes in each of the 3 hidden layers. This is the best model with the best performance in terms of MSE for Validation dataset which is very very slight improved from the model with 1 hidden layer and 2 hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2457ab6c580>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Validation MSE for all the 3 models on y axis with different number of hidden layers with their corresponding number of weights on x axis\n",
    "# Validation MSE of last epoch for each of the 3 models on y axis with their corresponding number of weights on x axis\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(model.count_params(),MSE_y_val[-1], label = 'Val_MSE_1_Hidden_layer')\n",
    "plt.scatter(model_layer_1.count_params(),MSE_y_val_layer[-1], label = 'Val_MSE_2_Hidden_layers')\n",
    "plt.scatter(model_layer_2.count_params(),MSE_y_val_layer_2[-1],label = 'Val_MSE_3_Hidden_layers' )\n",
    "plt.grid()\n",
    "plt.ylabel('MSE at last epoch')\n",
    "plt.xlabel('Number of Weights for each model with different number of hidden layers')\n",
    "plt.title('Plot of MSE vs Number of Weights')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2457ac07fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Validation MSE for all the 3 models on y axis having different number of hidden layers with number of hidden layers on x axis\n",
    "# Validation MSE of last epoch for each of the 3 models on y axis with their corresponding number of hidden layers on x axis\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(len(model.layers) - 1,MSE_y_val[-1], label = 'Val_MSE_1_Hidden_layer')\n",
    "plt.scatter(len(model_layer_1.layers) - 1, MSE_y_val_layer[-1], label = 'Val_MSE_2_Hidden_layers')\n",
    "plt.scatter(len(model_layer_2.layers) - 1,MSE_y_val_layer_2[-1], label = 'Val_MSE_3_Hidden_layers' )\n",
    "plt.grid()\n",
    "plt.ylabel('MSE at last epoch')\n",
    "plt.xlabel('Number of Hidden Layer changes')\n",
    "plt.title('Plot of MSE vs Number of Hidden Layers for each model')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Cost to achieve the best Validation is very high. To achieve almost the same Validation MSE not even 1% better it takes 3 times the computation cost than the basic model with 1 hidden layer. To spend 3 times more on Computation to achieve less than 1% better Validation MSE using the 3 hidden layers is not acceptable. So, increasing the number of hidden layers gives slight better performance but it doesn't help rather increases the computation cost by 3 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2457ac5c640>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Computational Cost calculated earlier for all the 3 models with different number of hidden layers on x axis and MSE of last epoch for that corresponding model on y axis\n",
    "# Conmputational Cost for 3 different models on x axis vs MSE of last epoch for these 3 models on y axis\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(epoch_x_mul_1[-1],MSE_y_val[-1], label = 'Val_MSE_1_Hidden_layer')\n",
    "plt.scatter(epoch_x_mul_2[-1],MSE_y_val_layer[-1], label = 'Val_MSE_2_Hidden_layers')\n",
    "plt.scatter(epoch_x_mul_3[-1],MSE_y_val_layer_2[-1],label = 'Val_MSE_3_Hidden_layers' )\n",
    "plt.grid()\n",
    "plt.ylabel('MSE at every epoch')\n",
    "plt.xlabel('Number of epochs * number of weights = Computational Cost')\n",
    "plt.title('Plot of MSE vs Computational Cost')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing the number of nodes/neurons while keeping the number of hidden layers constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 44)                528       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 44)                1980      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 45        \n",
      "=================================================================\n",
      "Total params: 2,553\n",
      "Trainable params: 2,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Keras Neural Networks Model with Input dimension as 11, 44 nodes in each of the 2 hidden layers, \n",
    "# 2 Hidden layers with sigmoid activation function and 1 output layer\n",
    "\n",
    "model_weight_1 = Sequential()\n",
    "model_weight_1.add(Dense(44, input_dim=X.shape[1], kernel_initializer='normal',use_bias=True, activation='sigmoid')) # 44 nodes in the 1st hidden layer\n",
    "model_weight_1.add(Dense(44, activation='sigmoid',use_bias=True)) # 44 nodes in the 2nd hidden layer\n",
    "model_weight_1.add(Dense(1, ))\n",
    "model_weight_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 66)                792       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 67        \n",
      "=================================================================\n",
      "Total params: 5,281\n",
      "Trainable params: 5,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Keras Neural Networks Model with Input dimension as 11, 66 nodes in each of the 2 hidden layers, \n",
    "# 2 Hidden layers with sigmoid activation function and 1 output layer\n",
    "\n",
    "model_weight_2 = Sequential()\n",
    "model_weight_2.add(Dense(66, input_dim=X.shape[1], kernel_initializer='normal',use_bias=True, activation='sigmoid')) # 66 nodes in the 1st hidden layer\n",
    "model_weight_2.add(Dense(66, activation='sigmoid',use_bias=True)) # 66 nodes in the 2nd hidden layer\n",
    "model_weight_2.add(Dense(1, ))\n",
    "model_weight_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and Metrics to be used for evaluation as MSE and Optimizer as Adam for model with 44 nodes in each of the 2 hidden layers\n",
    "\n",
    "model_weight_1.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and Metrics to be used for evaluation as MSE and Optimizer as Adam for model with 66 nodes in each of the 2 hidden layers\n",
    "\n",
    "model_weight_2.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.0435 - mse: 0.0435 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0341 - val_mse: 0.0341\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0318 - val_mse: 0.0318\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0088 - val_mse: 0.0088\n"
     ]
    }
   ],
   "source": [
    "# Training the NN model with scaled Input and Output with 100 Epochs and batch_size of 50 to see the MSE at each epoch \n",
    "# for training and validation split of the data for model 44 nodes in each of the 2 hidden layers\n",
    "\n",
    "history_weight_1 = model_weight_1.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0360 - val_mse: 0.0360\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0087 - val_mse: 0.0087\n"
     ]
    }
   ],
   "source": [
    "# Training the NN model with scaled Input and Output with 100 Epochs and batch_size of 50 to see the MSE at each epoch \n",
    "# for training and validation split of the data for model 66 nodes in each of the 2 hidden layers\n",
    "\n",
    "history_weight_2 = model_weight_2.fit(X_train, y_train, epochs=100, batch_size=50,  verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation mse for model with 44 nodes in each of the 2 hidden layers assigned to a variable\n",
    "\n",
    "MSE_y_weight_1_val = history_weight_1.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation mse for model with 66 nodes in each of the 2 hidden layers assigned to a variable\n",
    "\n",
    "MSE_y_weight_2_val = history_weight_2.history['val_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the product of number of weights, number of epochs and number of data points in each batch=50\n",
    "# for using it as Computational Cost for model with 44 nodes in each of the 2 hidden layers\n",
    "\n",
    "epoch_x_mul_4 = []\n",
    "for i in range (1,(len(history_weight_1.epoch)+1)):\n",
    "    epoch_x_mul_4.append(i * model_weight_1.count_params() * 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the product of number of weights, number of epochs and number of data points in each batch=50\n",
    "# for using it as Computational Cost for model with 66 nodes in each of the 2 hidden layers\n",
    "\n",
    "epoch_x_mul_5 = []\n",
    "for i in range (1,(len(history_weight_2.epoch)+1)):\n",
    "    epoch_x_mul_5.append(i * model_weight_2.count_params() * 50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation MSE does not improve by increasing the number of the weights in the hidden layers as the MSE is slightly worse than what it is with the basic model consisting 22 nodes rather 44 or 66 nodes. This is the best model with 22 nodes in each of the 2 hidden layers giving the best results after computing large number of weights and the MSE's. So, increasing the number of the weights does not help in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2457c54ab20>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MSE for each of the 3 models with 2 hidden layers and 22, 44 and 66 nodes varied in the hidden layers on y axis and \n",
    "# number of weights for these 3 models with different nodes in each of the 2 hidden layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(model_layer_1.count_params(),MSE_y_val_layer[-1], label = 'Val_MSE_2_Hidden_layers_22neurons')\n",
    "plt.scatter(model_weight_1.count_params(),MSE_y_weight_1_val[-1],label = 'Val_MSE_2_Hidden_layers_44neurons' )\n",
    "plt.scatter(model_weight_2.count_params(),MSE_y_weight_2_val[-1],label = 'Val_MSE_2_Hidden_layers_66neurons' )\n",
    "plt.grid()\n",
    "plt.ylabel('MSE at last epoch')\n",
    "plt.xlabel('Number of Weight changes for each model with different number of nodes')\n",
    "plt.title('Plot of MSE vs Number of weight changes caused by change in the number of nodes in the hidden layers')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the very first place the Validation MSE is not improved by increasing the number of the weights in the hidden layers. Now, considering the computational cost one would incur to achieve the this low Validation MSE of below 0.01 is 3 to 5 times more than the basic model. To spend 3 to 5 times more on the computation cost and not get any improvement in terms of the MSE for the Regression problem doesn't make sense to increase the number of nodes/weights keeping the number of the hidden layers constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24579e14910>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Computational Cost calculated earlier for all the 3 models with different number of nodes in each of the 2 hidden layers on x axis \n",
    "# and MSE of last epoch for that corresponding model on y axis \n",
    "# Conmputational Cost for 3 different models on x axis vs MSE of last epoch for these 3 models on y axis with different number of nodes in each of the hidden layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(epoch_x_mul_2[-1],MSE_y_val_layer[-1], label = 'Val_MSE_2_Hidden_layers_22neurons')\n",
    "plt.scatter(epoch_x_mul_4[-1],MSE_y_weight_1_val[-1],label = 'Val_MSE_2_Hidden_layers_44neurons' )\n",
    "plt.scatter(epoch_x_mul_5[-1],MSE_y_weight_2_val[-1],label = 'Val_MSE_2_Hidden_layers_66neurons' )\n",
    "plt.grid()\n",
    "plt.ylabel('MSE at last epoch')\n",
    "plt.xlabel('Number of epochs * number of weights = Computational Cost')\n",
    "plt.title('Plot of MSE vs Computational Cost')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Increasing the number of the layers: Keeping the number of the weights constant in the hidden layers and increasing the number of the hidden layers from 1 to 3 in a step of 1, gave results which indicated there was a very slight improvement in the Validation MSE if the number of the hidden layers were increased but this slight increase in the MSE performance had a very huge implication of Computation Cost increasing drastically by 3 times making it not advisable to increase the increase the number of the hidden layers as it doesn't help. There is no point in spending 3 times more on the computational cost which not even getting 1% more improvement on the Validation MSE. The Best results obtained were Validation MSE of 0.0084 for the model with 3 hidden layers, MSE of 0.0086 for 2 hidden layers network and MSE of 0.0087 for network with single hidden layer keeping the number of nodes same as 22. The Validation MSE reduces at a faster rate for the model with 1 hidden layer as compared to model with 2 or 3 hidden layers. The loss is reducing at a higher rate for the model with single hidden layer rather than models with higher number of hidden layers 2 or 3.\n",
    "\n",
    "## 2. Increasing the number of the Weights/Nodes: Keeping the number of the hidden layers to be constant at 2 and increasing the number of the weights in ech of the hidden layers from 22 to 66 in steps of 22, showed that Validation MSE was almost the same for all the 3 cases but slightly better for model with 22 neurons. Increasing the number of the weights did not improve the Validation MSE. Now, coming to the Computational Cost it would incur to do this is huge. For 44 neurons network, the computional cost goes up by 3 times and for 66 neurons network, the computional cost goes up by 5 times as compared to the model with 22 neurons. So, on both the fronts of Validation MSE and Computational Cost increasing the number of the weights doesn't help in this case. The Best results obtained were Validation MSE of 0.0086 for the model with 22 nodes in each of the 2 hidden layers, MSE of 0.00885 for the model with 44 nodes in each of the 2 hidden layers and MSE of 0.00865 for network with 66 nodes in each of the 2 hidden layers. The MSE is slightly increasing when increasing (becoming worse) the number of weights. The MSE is almost the same but the computational cost is huge.\n",
    "\n",
    "## For other cases or problems, this may change due to the nature of the problem which may be different due to the different attributes of the data and can also be due to the size and type of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
